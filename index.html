<!DOCTYPE html>
<html>

<head>
    <title>KokoMind: Can Large Language Models Understand Social Interactions?</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="website/css/style.css">
    <link rel="icon" href="website/img/gorilla.png" type="image/icon type">

    <script src="https://code.hcharts.cn/highcharts/highcharts.js"></script>
    <script src="https://code.hcharts.cn/highcharts/modules/exporting.js"></script>
    <script src="https://code.hcharts.cn/highcharts/modules/sankey.js"></script>>
</head>

<body>
    <div id="nav">
        <div id="icon">
            <a id="nav-button-kokomind" class="nav-button" href="#">KokoMind
            </a>
        </div>
        <div>
            <a class="nav-button" href="#introduction">Introduction</a>
            <a class="nav-button" href="#dataset">Dataset</a>
            <a class="nav-button" href="https://github.com/CHATS-lab/KokoMind">Download</a>
            <a class="nav-button" href="#evaluation">Results</a>
            <a class="nav-button" href="#limitation">Limitations</a>
            <a class="nav-button" href="#license">License</a>
            <a class="nav-button" href="#acknowledgement">Acknowledgement</a>
            <a class="nav-button" href="#citation">Citation</a>
        </div>
    </div>

    <div class="container">
        <div class="myhead" style="margin-bottom: -1em;">
            <div class="row">
                <div class="col-md-2">
                    <img src="website/img/gorilla.png" alt="gorilla logo" width="100">
                </div>
                <div class="col-md-8">
                    <h1>
                        <span style="color: var(--koko-color)">Koko</span><span
                            style="color: var(--mind-color)">Mind</span>: Can LLMs Understand Social Interactions?
                    </h1>
                </div>
            </div>
            <div class="row">
                <h3 class="blog-author">Authors:
                    <a href="https://wyshi.github.io/">Weiyan Shi<sup>*</sup></a> and
                    <a href="https://www.lqiu.info/">Liang Qiu<sup>*</sup></a> and
                    <a href="https://www.linkedin.com/in/dehong-xu-61a947248/">Dehong Xu</a> and
                    <a href="https://scholar.google.com/citations?user=rPB_BiwAAAAJ&hl=en">Pengwei Sui</a> and
                    <a href="https://lupantech.github.io/">Pan Lu</a> and
                    <a href="https://www.cs.columbia.edu/~zhouyu/">Zhou Yu</a>
                </h3>
                <p style="font-size: 16px;">
                    <i>&nbsp;&nbsp; <strong>TL;DR:</strong> We introduce <span
                            style="color: var(--koko-color);">Koko</span><span
                            style="color: var(--mind-color)">Mind</span>, a dataset with multi-party social interactions
                        to evaluate LLMs' social understanding abilities. GPT-4 tops the list, followed by Claude.</i>
                </p>
            </div>
        </div>
    </div>

    <br>
    <div class="container">
        <section id="introduction">
            <h2>Introduction: Imagine an AI ü§ñ at a cocktail party üçª </h2>
            <p>
                <a href="https://github.com/CHATS-lab/KokoMind"><b>[Download KokoMind to evaluate your own
                        models!]</b></a>
                <br><br>
                Imagine this: you're at a vibrant cocktail party üçπ, filled with the buzz of conversation and the clink
                of
                glasses üçª. You're
                a laid-back observer üëÄ, tucked comfortably in a corner. Yet, you can still easily figure out the social
                relations between
                different people, understand what's going on, and even provide social suggestions by reading people's
                verbal and
                non-verbal cues.
                <br>
                <br>
                If a large language model (LLM) could replicate this level of social aptitude, then we could say that it
                possesses
                certain social abilities. Curious how different LLMs perform when it comes to understanding and
                navigating social
                interactions? Check out these demos processed by AI models<sup>&#x2666;</sup>!
                <br>
                <font size="2">
                    <sup>&#x2666;</sup> These videos are transcribed by <a
                        href="https://openai.com/research/whisper">Whisper</a>.<br>
                    <sup>&#x2666;</sup> <a href="https://chat.openai.com/">ChatGPT</a>, a text-only model, is predicting
                    emotions and
                    answering questions by reading the
                    interaction. <br>
                    <sup>&#x2666;</sup> <a href="https://chat.openai.com/">ChatGPT</a> also reads the conversation and
                    answers
                    different
                    questions related to social
                    understanding.<br>
                    <sup>&#x2666;</sup> For reference, <a
                        href="https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K">CLIP</a>, a
                    vision-only model is also predicting facial expressions by looking at the
                    face.
                </font>
            </p>

        </section>
        <div class="tabs">
            <input type="radio" name="tabs" id="tabone" checked="checked">
            <label for="tabone">Demo 1</label>
            <div class="tab">
                <p>Shrinking S01 E03 I Cried 4 Times Today</p>
                <div class="demo">
                    <iframe src="website/video/demo1.mp4" frameborder="0" webkitallowfullscreen mozallowfullscreen
                        allowfullscreen
                        style="position: absolute; clip-path: inset(2px 2px); top: 0; left: 0; width: 100%; height: 100%;">
                    </iframe>
                </div>
            </div>

            <input type="radio" name="tabs" id="tabtwo">
            <label for="tabtwo">Demo 2</label>
            <div class="tab">
                <p>Shrinking S01 E06 Just a Normal Day</p>
                <div class="demo">
                    <iframe src="website/video/demo2.mp4" frameborder="0" webkitallowfullscreen mozallowfullscreen
                        allowfullscreen
                        style="position: absolute; clip-path: inset(2px 2px); top: 0; left: 0; width: 100%; height: 100%;">
                    </iframe>
                </div>
            </div>

            <input type="radio" name="tabs" id="tabthree">
            <label for="tabthree">Demo 3</label>
            <div class="tab">
                <p>Shrinking S01 E07 You Wish</p>
                <div class="demo">
                    <iframe src="website/video/demo3.mp4" frameborder="0" webkitallowfullscreen mozallowfullscreen
                        allowfullscreen
                        style="position: absolute; clip-path: inset(3px 3px); top: 0; left: 0; width: 100%; height: 100%;">
                    </iframe>
                </div>
            </div>
        </div>

        <br>
        <section id="dataset">
            <h2><img src="website/img/gorilla.png" alt="gorilla logo" width="36">&nbsp;<span
                    style="color: var(--koko-color)">Koko</span><span style="color: var(--mind-color)">Mind</span>: A
                Multifaceted Evaluation Dataset of Social Interactions
            </h2>
            <p>
                <span style="color: var(--koko-color)">Koko</span><span style="color: var(--mind-color)">Mind</span>
                contains 150 complex multi-party social interactions (50 per source) with free-text
                questions
                and
                answers.
                To ensure diversity and
                scalability and
                avoid data contamination, all the social interactions, questions, and answers are generated by GPT-4 and
                verified by
                human experts later.
                These generations are based on three different sources:
                <br>
            </p>
            <ul>
                <li><b>ü§ñ GPT-4-only</b>: This subset is created solely by GPT-4 through
                    prompting, without grounding on existing sources.</li>
                <li><b>üé¶ Movie-based</b>: To avoid data contamination, this portion of the data is grounded
                    on
                    diverse scenarios pulled from movies released after
                    2022. GPT-4 shapes these situations, maintaining the core essence while adding its own elements.
                </li>
                <li><b>üß† ToMi-based</b>: This segment contains data backboned by a simulated dataset, <a
                        href="https://github.com/facebookresearch/ToMi">ToMi</a>, which involves moving physical objects
                    to different places, a classic test for theory of mind. These social interactions are again
                    embellished and expanded by
                    GPT-4.
                </li>
            </ul>
            <p>
                For each social interaction, we ask various questions designed to probe the following aspects of social
                understanding.
                <br>
            <ul>
                <li><b>üß† Theory of Mind</b>: Questions evaluating understanding of others' mental states and
                    perspectives.
                </li>
                <li><b>üëç Social Norm</b>: Questions aiming to discern societal values and norms within the
                    situations.
                </li>
                <li><b>üòÉ Emotion Recognition</b>: Questions targeted at identifying and understanding emotional
                    elements within
                    the
                    context.
                </li>
                <li><b>üë®‚Äçüë©‚Äçüëß Social Relation</b>: Queries focusing on interpersonal dynamics and relationships.
                </li>
                <li><b>ü§î Counterfactual Questions</b>: Hypothetical queries designed to explore alternative
                    outcomes or
                    possibilities.</li>
                <li><b>üìù Social Advice</b>: Questions eliciting advice or action recommendations relevant to
                    the
                    given
                    situation.</li>
            </ul>
            </p>
            <h3>
                <div style="text-align: center">
                    Check out these examples in <img src="website/img/gorilla.png" alt="gorilla logo"
                        width="36">&nbsp;<span style="color: var(--koko-color)">Koko</span><span
                        style="color: var(--mind-color)">Mind</span>!
                </div>
            </h3>
            <div class="text-container">
                <div class="row">
                    <div class="col">
                        <form action="#">
                            <label for="source-select"
                                style="display: block;margin: -8px -2px;font-size: 18px;">Source</label>
                            <select name="source-select" id="source-select" onchange="change_context()">
                                <option value="general">GPT-4-only</option>
                                <option value="movie">Movie-based</option>
                                <option value="tomi">ToMi-based</option>
                            </select>

                        </form>
                    </div>

                    <div class="col">
                        <form action="#">
                            <label for="question-select"
                                style="display: block;;margin: -8px -2px;font-size: 18px;">Question
                                Type</label>
                            <select name="question-select" id="question-select" onchange="change_question()">
                                <option value="tom">Theory of Mind</option>
                                <option value="social_norm">Social Norm</option>
                                <option value="emotion">Emotion Recognition</option>
                                <option value="social_relation">Social Relation</option>
                                <option value="counterfactual">Counterfactual</option>
                                <option value="social_advice">Social Advice</option>
                            </select>
                        </form>
                    </div>
                </div>
                <div class="text-box" style="margin: 10px;">
                    <div class="text-wrapper">
                        <div class="text">
                            <h4> <strong>Interaction:</strong> </h4>
                            <gen id="generation">
                                Jun (<span class="tag emotion">nervously sipping coffee</span>
                                <span class="tag gender">Male</span>
                                <span class="tag age">28</span>
                                <span class="tag role">marketing executive</span>): I simply don't understand
                                why
                                things
                                got
                                so heated...<br />
                                Kyung (<span class="tag emotion">unsure</span>
                                <span class="tag gender">Female</span>
                                <span class="tag age">32</span>
                                <span class="tag role">nurse</span>): Maybe it's just a misunderstanding. Don't
                                worry
                                too
                                much
                                about it.<br />
                                Min (<span class="tag emotion">displeased</span>
                                <span class="tag gender">Male</span>
                                <span class="tag age">24</span>
                                <span class="tag role">student</span>): I couldn't even hear what Ji-ho was
                                whispering
                                about
                                earlier.<br />
                                Hana (<span class="tag emotion">surprised</span>
                                <span class="tag gender">Female</span>
                                <span class="tag age">45</span>
                                <span class="tag role">housewife</span>): I must've missed that too.<br />
                                Ji-ho (<span class="tag emotion">whispering to Hae-won</span>
                                <span class="tag gender">Male</span>
                                <span class="tag age">40</span>
                                <span class="tag role">manager</span>): You've noticed the tension too,
                                right?<br />
                                Hae-won (<span class="tag emotion">whispers back</span>
                                <span class="tag gender">Female</span>
                                <span class="tag age">35</span>
                                <span class="tag role">teacher</span>): Yes, Ji-ho. But I think it's best if we
                                don't
                                get involved.<br />
                                Dae (<span class="tag emotion">jovial</span>
                                <span class="tag gender">Male</span>
                                <span class="tag age">55</span>
                                <span class="tag role">gardener</span>): Oh, come on, everyone! We're here to
                                enjoy
                                our
                                time
                                together.<br />
                                Jin (<span class="tag emotion">quietly concerned</span>
                                <span class="tag gender">Female</span>
                                <span class="tag age">60</span>
                                <span class="tag role">retired</span>): I hope nothing worse happens out of this
                                situation.<br />
                                Eun (<span class="tag emotion">unaware of what's happening</span>
                                <span class="tag gender">Male</span>
                                <span class="tag age">22</span>
                                <span class="tag role">barista</span>): Enjoy your coffee and pastries!<br />
                                Soo-min (<span class="tag emotion">troubled but smiling</span>
                                <span class="tag gender">Female</span>
                                <span class="tag age">52</span>
                                <span class="tag role">artist</span>): Let's try to put this behind us and think
                                positively.<br />
                            </gen>
                        </div>
                    </div>
                </div>
                <div class="text-box">
                    <div class="text-wrapper">
                        <div class="text">
                            <span> <strong>Question:</strong> </span>
                            <gen id="question">
                                In Hae-won's mind, what does she think Ji-ho is feeling about the tension in the
                                group?
                            </gen>
                        </div>
                        <div class="text">
                            <span> <strong>Answer:</strong> </span>
                            <gen id="answer">Hae-won thinks Ji-ho is concerned about the tension in the group.
                            </gen>
                        </div>
                    </div>
                </div>
            </div>
            <h3>
                <div style="text-align: center;">
                    <img src="website/img/gorilla.png" alt="gorilla logo" width="36">&nbsp;Here is the data
                    distribution!
                    <br>
                </div>
            </h3>
            <div id="container"></div>
        </section>
        <br>

        <section id="evaluation">
            <h2>Results: GPT-4 tops the list, followed by Claude in many cases</h2>
            We evaluated different models following <a href="https://github.com/tatsu-lab/alpaca_eval">AlpacaEval</a>
            with text-davinci-003 as reference,
            and performed an ablation study, where we removed non-verbal cues in the parenthesis (e.g., nervously
            sipping coffee, etc) from the context. Here are some interesting takeaways.
            <br>
            <br>
            <ul>
                <li>Among the two LLM-based evaluators, GPT-4 exhibits greater certainty and confidence in identifying
                    the
                    winning model, in comparison to Claude.</li>
                <li>When the context has no non-verbal cues, and the interaction is either solely generated by
                    GPT-4 or grounded on movies, Claude performs better than GPT-4 (agreed by both evaluators); while if
                    the
                    context contains non-verbal cues, GPT-4 is always better than Claude. One possible explanation is
                    GPT-4
                    is a multi-modal model, so as expected, it can better understand extra non-verbal information. Also
                    note
                    that
                    when presented with non-verbal cues, the LLM-based evaluator perceives that the top-performing
                    models
                    have a
                    more substantial advantage over less accomplished models.</li>
                <li>One may be wondering that if the social interactions are generated by GPT-4, does that mean GPT-4
                    can
                    already answer these questions? It seems that the source plays a smaller role compared to the type
                    of
                    questions.</li>
                <li>It appears that LLM-based evaluators find it easier to determine the superior model in tasks
                    unrelated
                    to theory-of-mind, especially from samples generated from ToMi dataset. This may be due to the fact
                    that
                    even the LLM evaluator may struggle to discern the correct answer in theory-of-mind contexts.</li>
                <li>Claude is good at giving social advice in many cases.</li>
            </ul>
            <h3>
                <div style="text-align: center">
                    <img src="website/img/gorilla.png" alt="gorilla logo" width="36">&nbsp;Play around with these
                    results!
                </div>
            </h3>
            <div class="text-container">
                <div class="row">
                    <div class="col-md-6" style="border-right: 3px solid #ddd;">
                        <div class="row">
                            <div class="col">
                                <form action="#">
                                    <label for="fig-reviewer"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Evaluator</label>
                                    <select name="fig-reviewer"
                                        style="background: var(--koko-color); border: 10px solid var(--koko-color)"
                                        id="fig-reviewer" onchange="fig_change()">
                                        <option value="reviewer-gpt4">GPT-4</option>
                                        <option value="reviewer-claude">Claude v1.3</option>
                                    </select>

                                </form>
                            </div>

                            <div class="col">
                                <form action="#">
                                    <label for="fig-context"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Context</label>
                                    <select name="fig-context"
                                        style="background: var(--koko-color); border: 10px solid var(--koko-color)"
                                        id="fig-context" onchange="fig_change()">
                                        <option value="context-emotion">w/ non-verbal cues</option>
                                        <option value="context-noemotion">w/o non-verbal cues</option>
                                    </select>
                                </form>
                            </div>
                            <div class="col">
                                <form action="#">
                                    <label for="fig-source"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Source</label>
                                    <select name="fig-source"
                                        style="background: var(--koko-color); border: 10px solid var(--koko-color)"
                                        id="fig-source" onchange="fig_change()">
                                        <option value="source-total">Total</option>
                                        <option value="source-general">GPT-4-only</option>
                                        <option value="source-movie">Movie-based</option>
                                        <option value="source-tomi">ToMi-based</option>
                                    </select>
                                </form>
                            </div>
                            <div class="col">
                                <form action="#">
                                    <label for="fig-question"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Question</label>
                                    <select name="fig-question"
                                        style="background: var(--koko-color); border: 10px solid var(--koko-color)"
                                        id="fig-question" onchange="fig_change()">
                                        <option value="question-total">Total</option>
                                        <option value="question-tom">Theory of Mind</option>
                                        <option value="question-social_norm">Social Norm</option>
                                        <option value="question-emotion">Emotion Recognition</option>
                                        <option value="question-social_relation">Social Relation</option>
                                        <option value="question-counterfactual">Counterfactual</option>
                                        <option value="question-social_advice">Social Advice</option>
                                    </select>
                                </form>
                            </div>
                        </div>
                        <div class="text-container">
                            <img id="fig" src="website/img/emotion_yes/gpt4/total/Total/win_rate.png">
                        </div>
                    </div>
                    <!-- <div class="link-top"></div> -->
                    <div class="col-md-6">
                        <div class="row">
                            <div class="col">
                                <form action="#">
                                    <label for="fig1-reviewer"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Evaluator</label>
                                    <select name="fig1-reviewer"
                                        style="background: var(--mind-color); border: 10px solid var(--mind-color)"
                                        id="fig1-reviewer" onchange="fig1_change()">
                                        <option value="reviewer-gpt4">GPT-4</option>
                                        <option value="reviewer-claude" ; selected>Claude v1.3</option>
                                    </select>

                                </form>
                            </div>

                            <div class="col">
                                <form action="#">
                                    <label for="fig1-context"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Context</label>
                                    <select name="fig1-context"
                                        style="background: var(--mind-color); border: 10px solid var(--mind-color)"
                                        id="fig1-context" onchange="fig1_change()">
                                        <option value="context-emotion">w/ non-verbal cues</option>
                                        <option value="context-noemotion">w/o non-verbal cues</option>
                                    </select>
                                </form>
                            </div>
                            <div class="col">
                                <form action="#">
                                    <label for="fig1-source"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Source</label>
                                    <select name="fig1-source"
                                        style="background: var(--mind-color); border: 10px solid var(--mind-color)"
                                        id="fig1-source" onchange="fig1_change()">
                                        <option value="source-total">Total</option>
                                        <option value="source-general">GPT-4-only</option>
                                        <option value="source-movie">Movie-based</option>
                                        <option value="source-tomi">ToMi-based</option>
                                    </select>
                                </form>
                            </div>
                            <div class="col">
                                <form action="#">
                                    <label for="fig1-question"
                                        style="display: block;margin: -8px -2px;font-size: 18px;">Question</label>
                                    <select name="fig1-question"
                                        style="background: var(--mind-color); border: 10px solid var(--mind-color)"
                                        id="fig1-question" onchange="fig1_change()">
                                        <option value="question-total">Total</option>
                                        <option value="question-tom">Theory of Mind</option>
                                        <option value="question-social_norm">Social Norm</option>
                                        <option value="question-emotion">Emotion Recognition</option>
                                        <option value="question-social_relation">Social Relation</option>
                                        <option value="question-counterfactual">Counterfactual</option>
                                        <option value="question-social_advice">Social Advice</option>
                                    </select>
                                </form>
                            </div>
                        </div>
                        <div class="text-container">
                            <img id="fig1" src="website/img/emotion_yes/claude/total/Total/win_rate.png">
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <br>

        <section id="limitation">
            <h2>Limitations</h2>
            <p>
                Our project, while exciting in many respects, does have certain limitations. First, the size of <span
                    style="color: var(--koko-color)">Koko</span><span style="color: var(--mind-color)">Mind</span>
                is relatively
                small, which could limit the broad applicability and comprehensiveness of our conclusions. Secondly, all
                of the
                interactions in <span style="color: var(--koko-color)">Koko</span><span
                    style="color: var(--mind-color)">Mind</span> are generated by GPT-4 and require human verification,
                which makes it hard to
                scale up the
                dataset. Besides, although
                <span style="color: var(--koko-color)">Koko</span><span style="color: var(--mind-color)">Mind</span>
                provides human-verfied answers in the dataset, we did not use these answers as a reference
                during evaluation, and as these answers are generated by GPT-4, they may be biased towards GPT-4 and
                future research can focus on how to evaluate models with human-verified machine-generated reference
                answers. Next, all the models we evaluated were versions prior to June 1, 2023. It is possible that
                newly released models may have better
                performance. Despite these limitations, we envision <span
                    style="color: var(--koko-color)">Koko</span><span style="color: var(--mind-color)">Mind</span> as a
                springboard for future
                investigations
                related to social
                intellignece, multi-modal language models, etc.
            </p>
        </section>

        <section id="license">
            <h2>License</h2>
            <p>
                This project is an early-stage research showcase, designed solely for non-commercial purposes. It
                adheres to <a href="https://openai.com/policies/terms-of-use">OpenAI's data usage terms</a>, and
                <a
                    href="https://chrome.google.com/webstore/detail/sharegpt-share-your-chatg/daiacboceoaocpibfodeljbdfacokfjb">ShareGPT's
                    privacy practices</a>. Let us know if you spot any
                potential
                violations. The software's code is available under the Apache License 2.0.
            </p>
        </section>

        <section id="acknowledgement">
            <h2>Acknowledgement</h2>
            <p>
                We would like to thank <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a> from UW,
                <a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a> from CMU, <a
                    href="https://scholar.google.com/citations?user=lMkTx0EAAAAJ&hl=en">Jason Weston</a> from Meta,
                and
                <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a> from Stanford for their
                enlightening
                dialogue and constructive input. The theoretical foundation of KokoMind is based on Liang's PhD research 
                with <a href="https://zhusongchun.net/">Song-Chun Zhu</a> from Peking University, Tsinghua University and 
                Beijing Institute for General Artificial Intelligence (BIGAI) and 
                <a href="https://scholar.google.com/citations?user=7k_1QFIAAAAJ&hl=en">Ying Nian Wu</a> from UCLA.
            </p>
        </section>

        <section id="citation">
            <h2>Citation</h2>
            <bib>
                @misc{kokomind2023, <br>
                &nbsp&nbsp title = {KokoMind: Can Large Language Models Understand Social Interactions?}, <br>
                &nbsp&nbsp url = {https://chats-lab.github.io/KokoMind/}, <br>
                &nbsp&nbsp author = {Shi, Weiyan and Qiu, Liang and Xu, Dehong and Sui, Pengwei and Lu, Pan and Yu,
                Zhou}, <br>
                &nbsp&nbsp month = {July}, <br>
                &nbsp&nbsp year = {2023} <br>
                }</bib>
        </section>
        <script src="website/scripts.js"></script>
    </div>
    <!-- <footer>
        <p>Thank you for visiting our webpage.</p>
        <p>To see the code for our project, please visit our GitHub repository at: <a href="[insert link here]">[insert
                link here]</a></p>
    </footer> -->
</body>

</html>